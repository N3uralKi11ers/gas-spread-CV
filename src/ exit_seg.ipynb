{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 12:31:37.461774: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-01 12:31:38.310598: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-01 12:31:39.357639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:31:39.431764: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:31:39.431980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "my_devices = tf.config.experimental.list_physical_devices(device_type='CPU') \n",
    "tf.config.experimental.set_visible_devices(devices=my_devices, device_type='CPU')\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPU, 1 Logical GPUs\n",
      "1 Physical CPU, 1 Logical CPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 12:31:39.440864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:31:39.441113: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:31:39.441265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:31:39.512376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:31:39.512608: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:31:39.512743: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:31:39.512872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4100 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus: \n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=4100)]\n",
    "    )\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "cpus = tf.config.list_physical_devices('CPU')\n",
    "logical_cpus = tf.config.list_logical_devices('CPU')\n",
    "print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_inp = \"../data_for_gan/input\"\n",
    "path_out = \"../data_for_gan/output\"\n",
    "input = []\n",
    "output1 = []\n",
    "output2 = []\n",
    "for root, dirs, files in os.walk(path_inp):\n",
    "    for file in files:\n",
    "        input.append(os.path.join(root, file))\n",
    "        output1.append(path_out+\"/\"+file[0]+\"/\"+file[0]+\"1.png\")\n",
    "        output2.append(path_out+\"/\"+file[0]+\"/\"+file[0]+\"2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../data_for_gan/input/4.jpg',\n",
       "  '../data_for_gan/input/3.jpg',\n",
       "  '../data_for_gan/input/5.png',\n",
       "  '../data_for_gan/input/1.jpg',\n",
       "  '../data_for_gan/input/6.jpg'],\n",
       " ['../data_for_gan/output/4/41.png',\n",
       "  '../data_for_gan/output/3/31.png',\n",
       "  '../data_for_gan/output/5/51.png',\n",
       "  '../data_for_gan/output/1/11.png',\n",
       "  '../data_for_gan/output/6/61.png'],\n",
       " ['../data_for_gan/output/4/42.png',\n",
       "  '../data_for_gan/output/3/32.png',\n",
       "  '../data_for_gan/output/5/52.png',\n",
       "  '../data_for_gan/output/1/12.png',\n",
       "  '../data_for_gan/output/6/62.png'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "# Custom loss function\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)  # Привести y_true к типу float32\n",
    "    # dice_loss = dice_coef(y_true, y_pred)\n",
    "    bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    return bce_loss\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1e-5):\n",
    "    y_true_f = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
    "    return (2.0 * intersection + smooth) / (union + smooth)\n",
    "\n",
    "NUM_EPOCHS=25\n",
    "IMG_WIDTH       = 512\n",
    "IMG_HEIGHT      = 512\n",
    "IMG_CHANNELS    = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 12:31:43.849028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:753] failed to allocate 4.00GiB (4299161600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "nb_filter = np.array([32,64,128,256,512]) / 2\n",
    "# Build U-Net++ model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "\n",
    "c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.5) (c1)\n",
    "c1 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "c1 = Dropout(0.5) (c1)\n",
    "p1 = MaxPooling2D((2, 2), strides=(2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.5) (c2)\n",
    "c2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "c2 = Dropout(0.5) (c2)\n",
    "p2 = MaxPooling2D((2, 2), strides=(2, 2)) (c2)\n",
    "\n",
    "up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(c2)\n",
    "conv1_2 = concatenate([up1_2, c1], name='merge12', axis=3)\n",
    "c3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_2)\n",
    "c3 = Dropout(0.5) (c3)\n",
    "c3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "c3 = Dropout(0.5) (c3)\n",
    "\n",
    "conv3_1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "conv3_1 = Dropout(0.5) (conv3_1)\n",
    "conv3_1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_1)\n",
    "conv3_1 = Dropout(0.5) (conv3_1)\n",
    "pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n",
    "\n",
    "up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n",
    "conv2_2 = concatenate([up2_2, c2], name='merge22', axis=3) #x10\n",
    "conv2_2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_2)\n",
    "conv2_2 = Dropout(0.5) (conv2_2)\n",
    "conv2_2 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_2)\n",
    "conv2_2 = Dropout(0.5) (conv2_2)\n",
    "\n",
    "up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n",
    "conv1_3 = concatenate([up1_3, c1, c3], name='merge13', axis=3)\n",
    "conv1_3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_3)\n",
    "conv1_3 = Dropout(0.5) (conv1_3)\n",
    "conv1_3 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_3)\n",
    "conv1_3 = Dropout(0.5) (conv1_3)\n",
    "\n",
    "conv4_1 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool3)\n",
    "conv4_1 = Dropout(0.5) (conv4_1)\n",
    "conv4_1 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_1)\n",
    "conv4_1 = Dropout(0.5) (conv4_1)\n",
    "pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n",
    "\n",
    "up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n",
    "conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=3) #x20\n",
    "conv3_2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_2)\n",
    "conv3_2 = Dropout(0.5) (conv3_2)\n",
    "conv3_2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_2)\n",
    "conv3_2 = Dropout(0.5) (conv3_2)\n",
    "\n",
    "up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n",
    "conv2_3 = concatenate([up2_3, c2, conv2_2], name='merge23', axis=3)\n",
    "conv2_3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_3)\n",
    "conv2_3 = Dropout(0.5) (conv2_3)\n",
    "conv2_3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_3)\n",
    "conv2_3 = Dropout(0.5) (conv2_3)\n",
    "\n",
    "up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n",
    "conv1_4 = concatenate([up1_4, c1, c3, conv1_3], name='merge14', axis=3)\n",
    "conv1_4 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_4)\n",
    "conv1_4 = Dropout(0.5) (conv1_4)\n",
    "conv1_4 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_4)\n",
    "conv1_4 = Dropout(0.5) (conv1_4)\n",
    "\n",
    "conv5_1 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (pool4)\n",
    "conv5_1 = Dropout(0.5) (conv5_1)\n",
    "conv5_1 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv5_1)\n",
    "conv5_1 = Dropout(0.5) (conv5_1)\n",
    "\n",
    "up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
    "conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=3) #x30\n",
    "conv4_2 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_2)\n",
    "conv4_2 = Dropout(0.5) (conv4_2)\n",
    "conv4_2 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv4_2)\n",
    "conv4_2 = Dropout(0.5) (conv4_2)\n",
    "\n",
    "up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
    "conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=3)\n",
    "conv3_3 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_3)\n",
    "conv3_3 = Dropout(0.5) (conv3_3)\n",
    "conv3_3 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv3_3)\n",
    "conv3_3 = Dropout(0.5) (conv3_3)\n",
    "\n",
    "up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
    "conv2_4 = concatenate([up2_4, c2, conv2_2, conv2_3], name='merge24', axis=3)\n",
    "conv2_4 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_4)\n",
    "conv2_4 = Dropout(0.5) (conv2_4)\n",
    "conv2_4 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv2_4)\n",
    "conv2_4 = Dropout(0.5) (conv2_4)\n",
    "\n",
    "up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
    "conv1_5 = concatenate([up1_5, c1, c3, conv1_3, conv1_4], name='merge15', axis=3)\n",
    "conv1_5 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_5)\n",
    "conv1_5 = Dropout(0.5) (conv1_5)\n",
    "conv1_5 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (conv1_5)\n",
    "conv1_5 = Dropout(0.5) (conv1_5)\n",
    "\n",
    "nestnet_output_4 = Conv2D(3, (1, 1), activation='sigmoid', kernel_initializer = 'he_normal',  name='output_4', padding='same')(conv1_5)\n",
    "\n",
    "model = Model([inputs], [nestnet_output_4])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5*1e-6), loss=bce_dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image_and_mask(image_path, mask1_path, mask2_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (IMG_HEIGHT, IMG_WIDTH), method=\"bicubic\")\n",
    "    image = tf.cast(image, dtype=tf.float32) / 255.\n",
    "    mask1 = tf.io.read_file(mask1_path)\n",
    "    mask1 = tf.image.decode_png(mask1, channels=1)\n",
    "    mask1 = tf.image.resize(mask1, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    mask1 = ~tf.cast(mask1, dtype=tf.uint8)\n",
    "    mask2 = tf.io.read_file(mask2_path)\n",
    "    mask2 = tf.image.decode_png(mask2, channels=1)\n",
    "    mask2 = tf.image.resize(mask2, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    mask2 = ~tf.cast(mask2, dtype=tf.uint8)\n",
    "    mask1 = tf.expand_dims(mask1, axis=0)  # Добавить размерность спереди\n",
    "    mask2 = tf.expand_dims(mask2, axis=0)  # Добавить размерность спереди\n",
    "    mask1 = tf.squeeze(mask1, axis=-1)\n",
    "    mask2 = tf.squeeze(mask2, axis=-1)\n",
    "    mask = tf.stack([(~mask1 & ~mask2), mask1, mask2], axis=-1)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "input_dataset = tf.data.Dataset.from_tensor_slices(input)\n",
    "output1_dataset = tf.data.Dataset.from_tensor_slices(output1)\n",
    "output2_dataset = tf.data.Dataset.from_tensor_slices(output2)\n",
    "\n",
    "# Примените load_image_and_mask к каждому элементу внутри датасетов\n",
    "# input_dataset = input_dataset.map(load_image_and_mask, num_parallel_calls=AUTOTUNE)\n",
    "# output1_dataset = output1_dataset.map(load_image_and_mask, num_parallel_calls=AUTOTUNE)\n",
    "# output2_dataset = output2_dataset.map(load_image_and_mask, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Зипуйте датасеты вместе\n",
    "dataset = tf.data.Dataset.zip((input_dataset, output1_dataset, output2_dataset))\n",
    "dataset_train = dataset.map(load_image_and_mask, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 3) (1, 512, 512, 3)\n",
      "(1, 512, 512, 3) (1, 512, 512, 3)\n",
      "(1, 512, 512, 3) (1, 512, 512, 3)\n",
      "(1, 512, 512, 3) (1, 512, 512, 3)\n",
      "(1, 512, 512, 3) (1, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for x,y in dataset_train:\n",
    "    # for x,y,z in dat:\n",
    "    # plt.imshow(x)\n",
    "    # plt.show()\n",
    "    # plt.imshow(y[:,:,:,0])\n",
    "    # plt.show()\n",
    "    # plt.imshow(y[:,:,:,1])\n",
    "    # plt.show()\n",
    "    # plt.imshow(y[:,:,:,2])\n",
    "    # plt.show()\n",
    "    print(x.shape, y.shape)\n",
    "    # print(dat[0].shape, dat[1].shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 489ms/step - loss: 1.5385\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mod/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mod/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mod\", save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
