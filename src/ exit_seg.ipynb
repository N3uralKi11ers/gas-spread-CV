{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 12:39:31.489478: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-01 12:39:32.135759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-01 12:39:32.800253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:39:32.823452: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:39:32.823671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "my_devices = tf.config.experimental.list_physical_devices(device_type='CPU') \n",
    "tf.config.experimental.set_visible_devices(devices=my_devices, device_type='CPU')\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPU, 1 Logical GPUs\n",
      "1 Physical CPU, 1 Logical CPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 12:39:33.435891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:39:33.436221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:39:33.436420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:39:33.497615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:39:33.497785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:39:33.497913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-01 12:39:33.498022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4100 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus: \n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=4100)]\n",
    "    )\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "cpus = tf.config.list_physical_devices('CPU')\n",
    "logical_cpus = tf.config.list_logical_devices('CPU')\n",
    "print(len(cpus), \"Physical CPU,\", len(logical_cpus), \"Logical CPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_inp = \"../data_for_gan/input\"\n",
    "path_out = \"../data_for_gan/output\"\n",
    "input = []\n",
    "output1 = []\n",
    "output2 = []\n",
    "for root, dirs, files in os.walk(path_inp):\n",
    "    for file in files:\n",
    "        input.append(os.path.join(root, file))\n",
    "        output1.append(path_out+\"/\"+file[0]+\"/\"+file[0]+\"1.png\")\n",
    "        output2.append(path_out+\"/\"+file[0]+\"/\"+file[0]+\"2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../data_for_gan/input/4.jpg',\n",
       "  '../data_for_gan/input/3.jpg',\n",
       "  '../data_for_gan/input/5.png',\n",
       "  '../data_for_gan/input/1.jpg',\n",
       "  '../data_for_gan/input/6.jpg'],\n",
       " ['../data_for_gan/output/4/41.png',\n",
       "  '../data_for_gan/output/3/31.png',\n",
       "  '../data_for_gan/output/5/51.png',\n",
       "  '../data_for_gan/output/1/11.png',\n",
       "  '../data_for_gan/output/6/61.png'],\n",
       " ['../data_for_gan/output/4/42.png',\n",
       "  '../data_for_gan/output/3/32.png',\n",
       "  '../data_for_gan/output/5/52.png',\n",
       "  '../data_for_gan/output/1/12.png',\n",
       "  '../data_for_gan/output/6/62.png'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "# Custom loss function\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)  # Привести y_true к типу float32\n",
    "    # dice_loss = dice_coef(y_true, y_pred)\n",
    "    bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    return bce_loss\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1e-5):\n",
    "    y_true_f = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)\n",
    "    return (2.0 * intersection + smooth) / (union + smooth)\n",
    "\n",
    "NUM_EPOCHS=25\n",
    "IMG_WIDTH       = 512\n",
    "IMG_HEIGHT      = 512\n",
    "IMG_CHANNELS    = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=128,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    padding=\"same\",\n",
    "    use_bias=False,\n",
    "):\n",
    "    x = tf.keras.layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=padding,\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "    )(block_input)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input):\n",
    "    dims = dspp_input.shape\n",
    "    dspp_input = tf.keras.layers.BatchNormalization()(dspp_input)\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
    "    out_pool = tf.keras.layers.UpSampling2D(\n",
    "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"nearest\" # nearest\n",
    "    )(x)\n",
    "\n",
    "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
    "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
    "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
    "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
    "    output = convolution_block(x, kernel_size=1)\n",
    "    return output\n",
    "\n",
    "def DeeplabV3Plus(input_shape, num_classes):\n",
    "    model_input = tf.keras.Input(shape=input_shape)\n",
    "    resnet50 = tf.keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
    "    )\n",
    "    # print(len(resnet50.layers))\n",
    "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
    "    x = DilatedSpatialPyramidPooling(x)\n",
    "\n",
    "    input_a = tf.keras.layers.UpSampling2D(\n",
    "        size=(input_shape[0] // 4 // x.shape[1], input_shape[0] // 4 // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
    "\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    x = convolution_block(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = convolution_block(x)\n",
    "    x = tf.keras.layers.UpSampling2D(\n",
    "        size=(input_shape[0] // x.shape[1], input_shape[0] // x.shape[2]),\n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    model_output = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", activation=\"sigmoid\")(x)\n",
    "    return tf.keras.Model(inputs=model_input, outputs=model_output)\n",
    "model = DeeplabV3Plus((IMG_HEIGHT, IMG_WIDTH, 3), 3)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3*1e-4), loss=tf.keras.losses.CategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image_and_mask(image_path, mask1_path, mask2_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (IMG_HEIGHT, IMG_WIDTH), method=\"bicubic\")\n",
    "    image = tf.cast(image, dtype=tf.float32) / 255.\n",
    "    mask1 = tf.io.read_file(mask1_path)\n",
    "    mask1 = tf.image.decode_png(mask1, channels=1)\n",
    "    mask1 = tf.image.resize(mask1, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    mask1 = ~tf.cast(mask1, dtype=tf.uint8)\n",
    "    mask2 = tf.io.read_file(mask2_path)\n",
    "    mask2 = tf.image.decode_png(mask2, channels=1)\n",
    "    mask2 = tf.image.resize(mask2, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    mask2 = ~tf.cast(mask2, dtype=tf.uint8)\n",
    "    mask1 = tf.expand_dims(mask1, axis=0)  # Добавить размерность спереди\n",
    "    mask2 = tf.expand_dims(mask2, axis=0)  # Добавить размерность спереди\n",
    "    mask1 = tf.squeeze(mask1, axis=-1)\n",
    "    mask2 = tf.squeeze(mask2, axis=-1)\n",
    "    mask = tf.stack([(~mask1 & ~mask2), mask1, mask2], axis=-1)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "input_dataset = tf.data.Dataset.from_tensor_slices(input)\n",
    "output1_dataset = tf.data.Dataset.from_tensor_slices(output1)\n",
    "output2_dataset = tf.data.Dataset.from_tensor_slices(output2)\n",
    "\n",
    "# Примените load_image_and_mask к каждому элементу внутри датасетов\n",
    "# input_dataset = input_dataset.map(load_image_and_mask, num_parallel_calls=AUTOTUNE)\n",
    "# output1_dataset = output1_dataset.map(load_image_and_mask, num_parallel_calls=AUTOTUNE)\n",
    "# output2_dataset = output2_dataset.map(load_image_and_mask, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Зипуйте датасеты вместе\n",
    "dataset = tf.data.Dataset.zip((input_dataset, output1_dataset, output2_dataset))\n",
    "dataset_train = dataset.map(load_image_and_mask, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 3) (1, 512, 512, 3)\n",
      "(1, 512, 512, 3) (1, 512, 512, 3)\n",
      "(1, 512, 512, 3) (1, 512, 512, 3)\n",
      "(1, 512, 512, 3) (1, 512, 512, 3)\n",
      "(1, 512, 512, 3) (1, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for x,y in dataset_train:\n",
    "    print(x.shape, y.shape)\n",
    "    # print(dat[0].shape, dat[1].shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 12:52:45.505382: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 21s 155ms/step - loss: 194.0169\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 120.8947\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 81.5569\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 1s 171ms/step - loss: 70.5469\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 2s 411ms/step - loss: 66.8408\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 58.7479\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 51.7719\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 1s 148ms/step - loss: 46.3028\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 42.0498\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 2s 435ms/step - loss: 38.7689\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 36.6146\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 34.9484\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 32.8758\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 31.2896\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 2s 292ms/step - loss: 30.1004\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 29.0445\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 28.0025\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 27.2875\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 2s 419ms/step - loss: 26.5770\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 25.7466\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 25.2395\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 24.5878\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 1s 181ms/step - loss: 23.8159\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 2s 411ms/step - loss: 23.0395\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 22.1431\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 21.5235\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 2s 440ms/step - loss: 21.0128\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 19.9825\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 19.6214\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 18.9016\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 1s 272ms/step - loss: 18.5060\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 1s 197ms/step - loss: 18.0253\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 17.3145\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 1s 168ms/step - loss: 17.0636\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 2s 384ms/step - loss: 16.3287\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 15.7738\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 1s 153ms/step - loss: 15.1600\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 2s 435ms/step - loss: 14.4756\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 13.9845\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 13.3923\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 13.0084\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 12.5550\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 12.0506\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 11.5878\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 11.2159\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 2s 434ms/step - loss: 10.8396\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 10.5614\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 10.3495\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 2s 428ms/step - loss: 10.6528\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 10.1133\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 9.4976\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 2s 412ms/step - loss: 9.0747\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 8.8434\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 8.3377\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 7.8299\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 1s 288ms/step - loss: 7.7292\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 1s 174ms/step - loss: 7.3776\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 6.8838\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 6.7191\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 2s 378ms/step - loss: 6.4440\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 6.0359\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 5.7746\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 2s 420ms/step - loss: 5.8022\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 5.5984\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 5.5479\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 2s 421ms/step - loss: 5.2266\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 5.2884\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 5.0577\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 2s 406ms/step - loss: 4.9439\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.8375\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 4.8815\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 2s 444ms/step - loss: 4.7632\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.6267\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 4.5873\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 2s 437ms/step - loss: 4.5217\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.5320\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.4353\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.4026\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 2s 333ms/step - loss: 4.3941\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.3136\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.2920\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 1s 161ms/step - loss: 4.1857\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 2s 390ms/step - loss: 4.1674\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.1554\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 4.1496\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 2s 430ms/step - loss: 4.0787\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 4.0138\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 3.9763\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 2s 418ms/step - loss: 3.9643\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 3.9347\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 3.9522\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 2s 435ms/step - loss: 3.8979\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 3.8103\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 3.9026\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 2s 421ms/step - loss: 3.7931\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 3.7360\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 3.7303\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 2s 437ms/step - loss: 3.7204\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 3.6740\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 3.6326\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mod/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mod/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mod\", save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
